---
fontsize: 8pt
format:
    beamer:
        include-in-header: "3_Header.tex"
bibliography: 3_Referenzen.bib
csl: https://www.zotero.org/styles/apa
---

#  {.plain}
\center
```{r, echo = FALSE, out.width = "20%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_otto.png")
```


\huge
Evaluation und Metaanalyse
\vspace{4mm}

\large
MSc Klinische Psychologie und Psychotherapie   

SoSe 2024

\vspace{4mm}
\normalsize
Prof. Dr. Dirk Ostwald

#  {.plain}
\vfill
\center
\huge
\textcolor{black}{(3) Standardisierte Effektstärkeschätzung}
\vfill

# 
\vfill
\setstretch{3}
\large
Motivation

Standardisierte Effektstärkeschätzung in Einzelstudien  

Anwendungsbeispiel

Selbstkontrollfragen
\vfill

# 
\vfill
\setstretch{3}
\large
**Motivation**

Standardisierte Effektstärkeschätzung in Einzelstudien

Anwendungsbeispiel

Selbstkontrollfragen
\vfill

# Motivation

\small
Was Eysenck right after all? A reassessment of the effects of psychotherapy for adult depression

\footnotesize
"We used a database of randomised trials of psychotherapies for adult depression that has been described
in a methods paper (Cuijpers et al. 2008a). The general methods we have used in this paper
have been described in a manual that is freely available (Cuijpers, 2016b). In brief, the database was developed
through a comprehensive literature search (from 1966 until 1 January 2017), and is updated every year. We
searched major bibliographical databases (PsycINFO, PubMed, Embase, Cochrane Central Register of
Controlled Trials). The full search string for PubMed is given in Appendix A.

In this database, we included all randomised trials in which at least one arm was a psychological treatment
for adults (>18 years) with a depressive disorder according to a diagnostic interview or an elevated level
of depressive symptomatology (as indicated by a score above a cut-off score on a validated self-report depression
scale). In the current study, we only used trials that compared a psychotherapy for adult depression
with a control group (waiting list, care-as-usual, placebo or other; this last category included control conditions
that could not be categorised into one of the three categories, such as participation in online discussion
forums, in workshops on other subjects, routine care in general medical care or an information booklet).

**We calculated effect sizes (Hedges’ g) for each comparison between a psychotherapy and a comparison group.
We only included outcome measures that assess depressive symptoms.** If there is more than one measure of depression, 
these are pooled within the study, before the overall effects are pooled across studies."

\flushright
@cuijpers2019

# Motivation
\small
Was Eysenck right after all? A reassessment of the effects of psychotherapy for adult depression

```{r, echo = FALSE, out.width = "42%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_cuijpers_table.pdf")
```

\footnotesize
\flushright
@cuijpers2019


# Motivation
\small
Is psychotherapy effective? A re-analysis of treatments for depression

```{r, echo = FALSE, out.width = "45%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_munder_figure.pdf")
```

\footnotesize
\flushright
@munder2019


# Motivation
\vspace{2mm}
```{r, echo = FALSE, out.width = "90%"}
knitr::include_graphics("3_Abbildungen/eva_3_wissenschaft.pdf")
```

# Motivation

```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("3_Abbildungen/eva_3_frequentistische_inferenz.pdf")
```

# Motivation
Standardannahmen Frequentistischer Inferenz 

\footnotesize
 $\mathcal{M}$ sei ein Frequentistisches Inferenzmodell mit Stichprobenvariablen 
$\ups_1,...,\ups_n \sim p_\theta$.  Es wird angenommen, dass ein konkreter Datensatz 
$y \in \mathbb{R}^{n}$ eine der möglichen Realisierungen von $y = (\ups_1,...,\ups_n)^T$ ist.

Aus Frequentistischer Sicht kann man eine Studie unendlich oft wiederholen und
zu jedem Datensatz Schätzer oder Statistiken auswerten, z.B. das Stichprobenmittel:
\vspace{2mm}
\begin{itemize}
\begin{footnotesize}
\item[] Datensatz (1) : $y^{(1)} = \begin{pmatrix} y_1^{(1)} & \cdots &  y_n^{(1)} \end{pmatrix}$ mit $\bar{y}^{(1)} = \frac{1}{n}\sum_{i=1}^n y_i^{(1)}$
\item[] Datensatz (2) : $y^{(2)} = \begin{pmatrix} y_1^{(2)} & \cdots &  y_n^{(2)} \end{pmatrix}$ mit $\bar{y}^{(2)} = \frac{1}{n}\sum_{i=1}^n y_i^{(2)}$
\item[] Datensatz (3) : $y^{(3)} = \begin{pmatrix} y_1^{(3)} & \cdots &  y_n^{(3)} \end{pmatrix}$ mit $\bar{y}^{(3)} = \frac{1}{n}\sum_{i=1}^n y_i^{(3)}$
\item[] Datensatz (4) : $y^{(4)} = \begin{pmatrix} y_1^{(4)} & \cdots &  y_n^{(4)} \end{pmatrix}$ mit $\bar{y}^{(4)} = \frac{1}{n}\sum_{i=1}^n y_i^{(4)}$
\item[] Datensatz (5) : $y^{(5)} = ...$
\end{footnotesize}
\end{itemize}

Um die Qualität statistischer Methoden zu beurteilen betrachtet die Frequentistische
Statistik deshalb die Wahrscheinlichkeitsverteilungen von Schätzern und Statistiken
unter Annahme von $\ups_1,...,\ups_n \sim p_\theta$. Was zum Beispiel ist die 
Verteilung der $\bar{y}^{(1)}$, $\bar{y}^{(2)}$, $\bar{y}^{(3)}$, $\bar{y}_n^{(4)}$, 
... also die Verteilung der Zufallsvariable $\bar{\ups}$?

Wenn eine statistische Methode im Sinne der Frequentistischen Standardannahmen
"gut" ist, dann heißt das also, dass sie bei häufiger Anwendung "im Mittel gut" ist.
Im Einzelfall, also im Normalfall nur eines vorliegenden Datensatzes, kann sie auch 
"schlecht" sein.

# Motivation
Standardproblemstellungen Frequentistischer Inferenz 

\small
\vspace{2mm}
\noindent (1) Parameterschätzung

Ziel der Parameterschätzung ist es, einen möglichst guten Tipp für wahre, aber unbekannte, 
Parameterwerte oder Funktionen dieser abzugeben, typischerweise mithilfe der Daten.

\vspace{2mm}
\noindent (2) Konfidenzintervalle

Ziel der Bestimmung von Konfidenzintervallen ist es, basierend auf der angenommenen
Verteilung der Daten eine quantitative Aussage über die mit Schätzwerten assoziierte 
Unsicherheit zu treffen.

\vspace{2mm}
\noindent (3) Hypothesentests

Ziel des Hypothesentestens ist es, basierend auf der angenommenen Verteilung der 
Daten in einer möglichst zuverlässigen Form zu entscheiden, ob ein wahrer, aber 
unbekannter Parameterwert in einer von zwei sich gegenseitig ausschließenden 
Untermengen des Parameterraumes liegt.

# 
\vfill
\setstretch{3}
\large
Motivation

**Standardisierte Effektstärkeschätzung in Einzelstudien**  

Anwendungsbeispiel

Selbstkontrollfragen
\vfill


# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize

Hedges' $g$ ist ein durch einen Multplikationsfaktor angepasstes Cohen's $d$, das
von  @hedges1981 und @hedges1985 eingeführt wurde. Grundlage für Hedges' $g$ ist 
die Frequentistische Verteilung von Cohen's $d$ in einem Normalverteilungsmodell der Daten
einer einzelnen Studie. In diesem Modell ist Cohen's $d$ ein verzerrter Schätzer der 
wahren, aber unbekannten, standardisierten Effektstärke, der Erwartungswert von Cohen's 
$d$ entspricht also nicht der wahren, aber unbekannten, standardisierten Effektstärke, 
Die Differenz zwischen dem Erwartungswert und der wahren, aber unbekannten, standardisierten 
Effekstärke, wird *Bias* genannt.

Im betrachtenten Normalverteilungsmodell kann der Bias von Cohen's $d$ analytisch 
bestimmt und numerisch approximiert werden. Die Bekanntheit des Bias erlaubt dann 
seine Korrektur durch Skalierung von Cohen's $d$ und der zur Biaskorrektur skalierte 
Wert von Cohen's $d$ wird *Hedges' $g$* genannt. Dabei ist der Bias von Cohen's 
$d$ für kleine Stichprobenumfänge am größten.

Letztlich ist Hedges' $g$ einfach der Tatsache geschuldet, dass Cohen's $d$ eng
mit der T-Statistik verwandt ist, die bekanntlich bei Nicht-Zutreffen der Nullhypothese
nichtzentral-$t$-verteilt ist und der Erwartungswert einer nichtzentralen-$t$-verteilten
Zufallsvariable nicht mit ihrem Nichtzentralitätsparameter identisch ist. Dabei
ist die Nicht-Normalität der Verteilung von Cohen's $d$ für größere Stichprobenumfänge
vernachlässigbar, was wiederum asymptotische Schätzungen der Varianz von Hedges' $g$
ermöglicht. 

Im Kontext von Metanalayse werden Hedges' $g$ und sein Varianzschätzer meist zunächst
für jede Einzelstudie bestimmt und dann über Studien, zum Beispiel mit den Fixed-Effects-
und Random-Effects-Modellen aus Einheit (4) integriert.

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\begin{definition}[Einzelstudienmodell]
\justifying
Es seien $y_{tj}$ für $j = 1,...,n_t$ und $y_{cj}$ für $j = 1,...,n_c$ die 
Zufallsvariablen, die die primären Ergebnismaße der $j$ten experimentellen Einheit 
in der Treatment- und der Kontrollgruppe einer Einzelstudie modellieren, respektive. 
Dann ist das Einzelstudienmodell (ESM) gegeben durch
\begin{align}
\begin{split}
y_{tj} & := \mu_t + \varepsilon_{tj}  \mbox{ mit }  \varepsilon_{tj} \sim N(0,\sigma^2) \mbox{ für } j = 1,...,n_t \\
y_{cj} & := \mu_c + \varepsilon_{cj}  \mbox{ mit }  \varepsilon_{cj} \sim N(0,\sigma^2) \mbox{ für } j = 1,...,n_c  \\
\end{split}
\end{align}
und die wahre, aber unbekannte, standardisierte Effekstärke (SES) ist definiert als
\begin{equation}
\delta := \frac{\mu_t - \mu_c}{\sigma}.
\end{equation}
\end{definition}

Bemerkungen

* Das Einzelstudienmodell ist offenbar identisch mit dem Zweistichproben-T-Test-Modell.
* Mit der Theorem zur linear-affinen Transformation von normalverteilten Zufallsvariablen gilt äquivalent
\begin{equation}
y_{tj} \sim N(\mu_t ,\sigma^2) \mbox{ für } j = 1,...,n_t  \mbox{ und }
y_{cj} \sim N(\mu_c ,\sigma^2) \mbox{ für } j = 1,...,n_c   
\end{equation}
* Die hier gewählte Formulierung entspricht @hedges1985 p. 76 (vgl. @lin2021)
* @hedges1981 formuliert ein äquivalentes  Modell basierend auf einer nicht-standardisierten Effektstärke.

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\begin{definition}[SES-Schätzer im Einzelstudienmodell]
\justifying
Gegeben sei ein Einzelstudienmodell mit wahrer, aber unbekannter, standardisierter Effektstärke 
$\delta \in \mathbb{R}$. Dann ist der \textit{Standardisierte Effektstärkeschätzer (SES-Schätzer)} $d$ von 
$\delta$ definiert als
\begin{equation}
d := \frac{\bar{y}_t - \bar{y}_c}{s},
\end{equation}
wobei 
\begin{equation}
\bar{y}_t := \frac{1}{n_t}\sum_{j=1}^{n_t} y_{tj} \mbox{ und }
\bar{y}_c := \frac{1}{n_c}\sum_{j=1}^{n_c} y_{cj} 
\end{equation}
die Stichprobenmittel der Treatment- und der Kontrollgruppe bezeichnen und $s$ 
die mithilfe der Stichprobenvarianzen
\begin{equation}
s_t^2 := \frac{1}{n_t - 1}\sum_{j=1}^{n_t}\left(y_{tj} - \bar{y}_t\right)^2 \mbox{ und }
s_c^2 := \frac{1}{n_c - 1}\sum_{j=1}^{n_c}\left(y_{cj} - \bar{y}_c\right)^2
\end{equation}
der Treatment- und Kontrollgruppe definierte \textit{gepoolte Stichprobenstandardabweichung} 
\begin{equation}
s := \sqrt{\frac{(n_t - 1)s_t^2 + (n_c - 1)s_c^2}{n_t + n_c - 2}}.
\end{equation}
bezeichnet.
\end{definition} 

Bemerkungen

* Der SES-Schätzer ist offenbar mit Cohen's $d$ identisch.
* Für den SES-Schätzer werden in $\delta$ lediglich $\mu_t$, $\mu_c$ und $\sigma$ durch ihre empirischen Äquivalente ersetzt. 

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\begin{theorem}[Eigenschaften des SES-Schätzer im ESM]
\justifying
\normalfont
Gegeben sei ein Einzelstudienmodell, es sei $d$ der Schätzer der wahren,
aber unbekannten, standardisierten Effektstärke $\delta$ und es seien 
\begin{equation}
n := \frac{n_t n_c}{n_t + n_c}, 
m := n_t + n_c - 2 \mbox{ und }
c_m = \frac{\Gamma(m/2)}{\sqrt{m/2}\Gamma((m-1)/2)}.
\end{equation}
Dann hat $d$ folgende Eigenschaften:
\begin{enumerate}
\item[(1)] $\sqrt{n} d \sim t(\sqrt{n}\delta,m)$,
\item[(2)] $\mathbb{E}(d) = \frac{1}{c_m}\delta$, und 
\item[(3)] $\mathbb{V}(d) = \frac{m}{(m - 2)n}(1 + n\delta^2) - \frac{1}{c_m^2}\delta^2$.
\end{enumerate}
\end{theorem}

Remarks

* $\sqrt{n}d$ ist eine nichtzentral-$t$-verteilte Zufallsvariable.
* Der Nichtzentralitätsparameter von $\sqrt{n}d$ ist $\sqrt{n}\delta$, der Freiheitsgradparameter ist $m$.
* Für die Definition nichtzentral-$t$-verteilter Zufallsvariablen und ihre Kennzahlen verweisen wir auf den Appendix.
* Für $\delta \neq 0$ und $c_m \neq 1$ impliziert (2), dass $\mathbb{E}(d) \neq \delta$.
* $d$ is also ein verzerrter Schätzer von von $\delta$.
 

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\underline{Beweis}

\noindent (1) Wir verzichten auf einen Beweis und verweisen wie @hedges1981 auf @johnson1940.

\noindent (2)  Mit dem Erwartungswert einer nichtzentral-$t$-verteilten Zufallsvariable ergibt sich 
\begin{equation}
\mathbb{E}(\sqrt{n}d) 
= \sqrt{n}\delta \sqrt{\frac{m}{2}} \frac{\Gamma((m-1)/2)}{\Gamma(m/2)}.
\end{equation}
Es ergibt sich also 
\begin{equation}
\mathbb{E}(d) 
= \frac{\sqrt{n}}{\sqrt{n}}\mathbb{E}(d)
= \frac{1}{\sqrt{n}}\mathbb{E}(\sqrt{n}d)
= \delta \sqrt{\frac{m}{2}} \frac{\Gamma((m-1)/2)}{\Gamma(m/2)}
= \frac{1}{c_m}\delta.
\end{equation}
\noindent (3) Mit der Varianzvon nichtzentral-$t$-verteilten Zufallsvariablen ergibt sich
\begin{align}
\begin{split}
\mathbb{V}(\sqrt{n}d) 
& =  \frac{m(1 + (\sqrt{n}\delta)^2)}{m-2}
   - \frac{(\sqrt{n}\delta^2)m}{2}\left(\frac{\Gamma((m-1)/2)}{\Gamma(m/2)} \right)^2 \\
& =  \frac{m}{m-2}(1 + n\delta^2)
   - n\delta^2\frac{m}{2}\left(\frac{\Gamma((m-1)/2)}{\Gamma(m/2)} \right)^2 \\
   & =  \frac{m}{m-2}(1 + n\delta^2) - n\delta^2\frac{1}{c_m^2}.
\end{split}
\end{align}
Es ergibt sich also 
\begin{equation}
\mathbb{V}(d) 
= \frac{n}{n}\mathbb{V}(d) 
= \frac{1}{n}\mathbb{V}(\sqrt{n}d)
= \frac{1}{n}\left(\frac{m}{m-2}(1 + n\delta^2) - n\delta^2\frac{1}{c_m^2} \right)
= \frac{m}{(m-2)n}(1 + n\delta^2) - \delta^2\frac{1}{c_m^2}.
\end{equation}

# Standardisierte Effektstärkeschätzung in Einzelstudien
\small
Verteilung von $\sqrt{n}d$

\footnotesize
$10^5$ SES-Schätzerrealisierungen mit $\delta = 2, n_t = 10, n_c = 10, m = 18, n = 5$  
\vspace{4mm}

\tiny
```{r, echo = T}
sim      = 1e5                                        # Anzahl Realisierungen
n_t      = 10                                         # Treatmentgruppenumfang
n_c      = 10                                         # Kontrollgruppenumfang
mu_t     = 2                                          # Erwartungswertparameter Treatment
mu_c     = 0                                          # Erwartungswertparameter Control
sigma    = 1                                          # Varianzparameter
delta    = (mu_t - mu_c)/sigma                        # wahre, aber unbekannte, SES
n        = (n_t*n_c/(n_t+n_c))                        # Stichprobenumfangparameter
m        = n_t + n_c - 2                              # Freiheitsgradparameter
c_m      = (gamma(m/2))/(sqrt(m/2)*gamma((m-1)/2))    # Biaskorrekturfaktor
ds       = rep(NaN, sim)                              # SES-Schätzerarrayinitialisierung
for(i in 1:sim){                                      # Simulationsiterationen
   y     = matrix(rep(NaN,n_t+n_c), ncol = 2)         # Datenanarrayinitialisierung  
   y[,1] = rnorm(n_t, mu_t, sigma)                    # Datengeneration Treatmentgruppe
   y[,2] = rnorm(n_c, mu_c, sigma)                    # Datengeneration Kontrollgruppe
   ybar  = apply(y,2,mean)                            # Gruppenmittelwerte   
   s2    = apply(y,2,var)                             # Gruppenvarianzen
   s     = sqrt(((n_t-1)*s2[1] + (n_c-1)*s2[2])/m)    # gepoolte Standardabweichung
   ds[i] = (ybar[1]-ybar[2])/s}                       # SES-Schätzerrealisierung   
```


# Standardisierte Effektstärkeschätzung in Einzelstudien
\small
Verteilung von $\sqrt{n}d$

\footnotesize
$10^5$ SES-Schätzerrealisierungen mit $\delta = 2, n_t = 10, n_c = 10, m = 18, n = 5$  
\vspace{2mm}

```{r, eval = F}
# figure setup
library(latex2exp)
pdf(file = "./3_Abbildungen/eva_3_d_verteilung.pdf", width = 6, height = 4)                                                                      
par(                                                                   
family      = "sans",                                                 
mfcol       = c(1,1),                                                
pty         = "m",                                                   
bty         = "l",                                                   
lwd         = 1,                                                      
las         = 1,                                                      
mgp         = c(2,1,0),                                               
xaxs        = "i",                                                    
yaxs        = "i",                                                    
font.main   = 1)  

# Histogramm
hist(
sqrt(n)*ds, 
breaks   = 100,                                                                         
col      = "gray90",                                                          
prob     = TRUE,                                                                                                                         
xlab     = TeX("$\\sqrt{n}d$"),                                                               
ylab     = "",  
ylim     = c(0,.4), 
xlim     = c(1,10),                                                              
main     = TeX("$\\sqrt{n}d \\sim t(\\sqrt{n}\\delta, m)$"))

# Analytische Verteilung
snd      = seq(1,10,len=1e2)    
lines(
snd,                                                                          
dt(snd,m,sqrt(n)*delta),                                                                        
lwd      = 2,                                                                 
col      = "darkorange")      
dev.off()
```

```{r, echo = FALSE, out.width = "80%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_d_verteilung.pdf")
```

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\begin{theorem}[Hegdes' $g$ im ESM]
\justifying
\normalfont
Gegeben sei ein Einzelstudienmodel, $d$ sei der verzerrte Schätzer von $\delta$ und es seien 
\begin{equation}
n := \frac{n_t n_c}{n_t + n_c}, 
m := n_t + n_c - 2 \mbox{ und }
c_m = \frac{\Gamma(m/2)}{\sqrt{m/2}\Gamma((m-1)/2)}.
\end{equation}
wie oben definiert. Dann ist 
\begin{equation}
g := c_m d,
\end{equation} 
genannt \textit{Hedges' $g$}, ein unverzerrter Schätzer von $\delta$ und es gilt 
\begin{equation}
\mathbb{V}(g) < \mathbb{V}(d).
\end{equation} 
\end{theorem}
\underline{Beweis}

Die Unverzerrtheit von $d_u$ ergibt sich aus 
\begin{equation}
\mathbb{E}(g) = \mathbb{E}(c_m d) = c_m\mathbb{E}(d) = c_m \frac{1}{c_m}\delta = \delta.
\end{equation}
Die Varianzreduktion von $d_u$ in Bezug auf $d$ folgt aus der Tatsache, dass $c_m < 1$ 
für alle $m$ und somit
\begin{equation}
\mathbb{V}(g) = \mathbb{V}(c_m d)  = c_m^2\mathbb{V}(d) <\mathbb{V}(d).
\end{equation}
$\hfill \Box$

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\vspace{2mm}
Bemerkungen

* Man beachte, dass der Korrekturfaktor $c_m$ durch $n_t + n_c - 2$ vom Gesamtstichprobenumfang abhängig ist.
* Der Wert des Korrekturfaktors für einen gegebenen Wert von $m$ kann sehr genau durch
\begin{equation}
c_m \approx 1 - \frac{3}{4m-1}
\end{equation}
angenähert werden, vgl. @hedges1981, @borenstein2009 und untenstehende Abbildung.

```{r, eval = F}
library(latex2exp)
pdf(file = "./3_Abbildungen/eva_3_c_m.pdf", width = 4, height = 4)                                                                      
par(                                                                   
family      = "sans",                                                 
mfcol       = c(1,1),                                                
pty         = "m",                                                   
bty         = "l",                                                   
lwd         = 1,                                                      
las         = 1,                                                      
mgp         = c(2,1,0),                                               
xaxs        = "i",                                                    
yaxs        = "i",                                                    
font.main   = 1) 
m           = 2:40                                            
c_m         = gamma(m/2)/(sqrt(m/2)*gamma((m-1)/2))           
c_m_a       = 1 - (3/(4*m-1))   
plot(
m, 
c_m,
type     = "l",
ylim     = c(.5,1.),
xlim     = c(0,40),
xlab     = TeX("$m$"),
ylab     = " ",
pch      =  19,
cex      =  1,
main     =  "",
lwd      = 3)
lines(
m,
c_m_a,
col      = "gray",
lty      = 2,
lwd      = 1)
legend(
"bottomright",
c(TeX("$c_m$"), TeX("$c_m$ Approximation")),
pch         = c(NaN,NaN),
lwd         = c(2,1),
lty         = c(1,2),
col         = c("black", "gray"),
bty         = "n",
cex         = 1,
x.intersp   = 1)
dev.off()
```
\vspace{-3mm}
```{r, echo = FALSE, out.width = "40%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_c_m.pdf")
```
\vspace{-3mm}

* @lin2021 zeigen in Appendix A1, dass  $c_m \to 1$ für $m \to \infty$.
* Die Biaskorrektur ist am wichtigsten bei Gesamtgruppengrößen $n_t + n_c < 30$.
* Die Biaskorrektur ist am wichtigsten bei Treatment- und Kontrollgruppengrößen $n_t = n_c < 15$.


# Standardisierte Effektstärkeschätzung in Einzelstudien

\vspace{2mm}

\small
Geschätzte Erwartungswerte der verzerrten und unverzerrten SES-Schätzer im ESM
\vspace{2mm}

\footnotesize
$10^5$ SES-Schätzerrealisierungen mit $\delta = 2, n_t = 10, n_c = 10, m = 18, n = 5$   
\vspace{2mm}


```{r, eval = F}
library(latex2exp)
pdf(file = "./3_Abbildungen/eva_3_d_bias_korrektur.pdf", width = 5, height = 4)                                                                      
par(                                                                   
family      = "sans",                                                 
mfcol       = c(1,1),                                                
pty         = "m",                                                   
bty         = "l",                                                   
lwd         = 1,                                                      
las         = 1,                                                      
mgp         = c(2,1,0),                                               
xaxs        = "i",                                                    
yaxs        = "i",                                                    
font.main   = 1) 
m           = 18
c_m         = (gamma(m/2))/(sqrt(m/2)*gamma((m-1)/2))
plot(
c(1,2),
c(mean(ds), mean(c_m*ds)),
type     = "p",
ylim     = c(1.5,2.5),
xlim     = c(0.5,2.5),
xaxt     = "n",
xlab     = "",
ylab     = "",
pch      =  19,
cex      =  1)
lines(
0:3,
rep(delta,4),
col      = "gray80",
lty      = 1)
axis(1, at = c(1,2), labels = c(TeX("$\\hat{E}(d)$"), TeX("$\\hat{E}(c_m d)$")))
dev.off()
```

```{r, echo = FALSE, out.width = "70%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_d_bias_korrektur.pdf")
```


# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\begin{theorem}[Asymptotische Normalverteilung von Hedges' $g$]
\justifying
\normalfont
Gegeben sei ein Einzelstudienmodel und $g$ sei der unverzerrte Schätzer von $\delta$.
Dann ist $g$ bei einem konstanten Verhältnis von $n_t$ und $n_c$ für $n_t \to \infty$, 
$n_c \to \infty$ asymptotisch normalverteilt und es gilt speziell
\begin{equation}
g \stackrel{a}{\sim} N\left(\delta, \frac{1}{n_t} + \frac{1}{n_c} + \frac{\delta^2}{2(n_t + n_c)}\right).
\end{equation}
\end{theorem}
\vspace{2mm}
Bemerkungen

* Wir erinnern daran, dass *Asymptotische Schätzereigenschaften* sich auf große Stichprobenumfänge beziehen.
* Das Theorem ist äquivalent dazu, dass die nichtzentrale-$t$-Verteilung für $\nu \to \infty$ die Normalverteilung annähert.
* Wir verzichten auf einen Beweis und verweisen wie @hedges1985 auf @johnson1940.




# Standardisierte Effektstärkeschätzung in Einzelstudien
\small
Asymptotische Normalverteilung von Hedges' $g$

\footnotesize
$10^5$ SES-Schätzerrealisierungen mit $\delta = 2$ für kleinen und großen Stichprobenumfang
\vspace{2mm}

\tiny
\setstretch{1.2}
```{r, echo = T}
sim            = 1e4                                           # Anzahl Realisierungen
mu_t           = 2                                             # Erwartungswertparameter Treatment
mu_c           = 0                                             # Erwartungswertparameter Control
sigma          = 1                                             # Varianzparameter
delta          = (mu_t - mu_c)/sigma                           # wahre, aber unbekannte, SES
ng             = c(10,100)                                     # Stichprobenumfänge
gs             = matrix(rep(NaN, 2*sim), ncol = 2)             # Hedges' g Arrayinitialisierung
vgs            = rep(NaN,2)                                    # asymptotische Varianzarray
for (j in 1:2){                                                # Stichprobenumfangsiterationen
   n_t         = ng[j]                                         # Treatmentgruppenumfang
   n_c         = ng[j]                                         # Kontrollgruppenumfang
   n           = (n_t*n_c/(n_t+n_c))                           # Stichprobenumfangparameter
   m           = n_t + n_c - 2                                 # Freiheitsgradparameter
   c_m         = (gamma(m/2))/(sqrt(m/2)*gamma((m-1)/2))       # Biaskorrekturfaktor
   vgs[j]      = (1/n_t)+(1/n_c)+(delta^2)/(2*(n_t+n_c))       # Asymptotische Varianz von Hedges' g
   for(i in 1:sim){                                            # Simulationsiterationen
      y        = matrix(rep(NaN,n_t+n_c), ncol = 2)            # Datenanarrayinitialisierung  
      y[,1]    = rnorm(n_t, mu_t, sigma)                       # Datengeneration Treatmentgruppe
      y[,2]    = rnorm(n_c, mu_c, sigma)                       # Datengeneration Kontrollgruppe
      ybar     = apply(y,2,mean)                               # Gruppenmittelwerte   
      s2       = apply(y,2,var)                                # Gruppenvarianzen
      s        = sqrt(((n_t-1)*s2[1] + (n_c-1)*s2[2])/m)       # gepoolte Standardabweichung
      gs[i,j] = c_m*(ybar[1]-ybar[2])/s}}                      # Hedges' g                  
```

# Standardisierte Effektstärkeschätzung in Einzelstudien
\small
Asymptotische Normalverteilung von Hedges' $g$

\footnotesize
$10^5$ SES-Schätzerrealisierungen mit $\delta = 2$ für kleinen und großen Stichprobenumfang
\vspace{2mm}

```{r, eval = F}
# figure setup
library(latex2exp)
pdf(file = "./3_Abbildungen/eva_3_g_verteilung.pdf", width = 8, height = 4)                                                                      
par(                                                                   
family      = "sans",                                                 
mfcol       = c(1,2),                                                
pty         = "m",                                                   
bty         = "l",                                                   
lwd         = 1,                                                      
las         = 1,                                                      
mgp         = c(2,1,0),                                               
xaxs        = "i",                                                    
yaxs        = "i",                                                    
font.main   = 1)  
lab         = c(TeX("$n_t = n_c = 10$"), TeX("$n_t = n_c = 100$"))
g           = seq(0,4,len=1e2)
for(j in 1:2){
   hist(
   gs[,j], 
   breaks   = 30,                                                      
   col      = "gray90",                                                          
   prob     = TRUE,                                                                                                                         
   xlab     = TeX("$g$"),                                                               
   ylab     = "",  
   xlim     = c(0,4),    
   ylim     = c(0,2.5),                                                  
   main     = lab[j])
   lines(
   g,                                                                          
   dnorm(g,delta,sqrt(vgs[j])),                                                                        
   lwd      = 2,                                                                 
   col      = "darkorange")   
}   
dev.off()
```


```{r, echo = FALSE, out.width = "100%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_g_verteilung.pdf")
```


# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\begin{definition}[Asymptotische Varianz und Varianzschätzer von Hedges $g$]
Gegeben sei ein Einzelstudienmodel und für den 
\begin{equation}
g \stackrel{a}{\sim} N\left(\delta, \frac{1}{n_t} + \frac{1}{n_c} + \frac{\delta^2}{2(n_t + n_c)}\right).
\end{equation}
Dann wird der Varianzparameter der asymptotischen Verteilung von $g$ die \textit{asymptotische Varianz} 
von $g$ genannt und mit 
\begin{equation}
\mathbb{V}_{a}(g) = \frac{1}{n_t} + \frac{1}{n_c} + \frac{\delta^2}{2(n_t + n_c)}.
\end{equation}
bezeichnet. Ein häufig genutzter Schätzer für die asymptotische Varianz von Hedges' $g$ ist
\begin{equation}
\hat{\mathbb{V}}_{a}(g) = \frac{1}{n_t} + \frac{1}{n_c} + \frac{g^2}{2(n_t + n_c)}.
\end{equation}
\end{definition}

* $\hat{\mathbb{V}}_{a}(g)$  wird häufig für die metananalytische Modellbildung genutzt, vgl. Einheit (4) und @lin2021.
* Bei konstantem Wert von Hegdes $g$ nimmt $\hat{\mathbb{V}}_{a}(g)$ offenbar bei steigenden Werten von $n_t$ und $n_c$ ab.

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\begin{theorem}[Asymptotisches Konfidenzintervall für die SES]
\justifying
\normalfont
Gegeben sei ein Einzelstudienmodel, $g$ sei der unverzerrte Schätzer der standardisierten
Effektstäkre $\delta$ und für ein Konfidenzlevel $\gamma \in ]0,1[$ sei
\begin{equation}
z_\gamma := \Phi^{-1}\left(\frac{1+\gamma}{2}\right)
\end{equation}
wobei $\Phi^{-1}$ die inverse kumulative Verteilungsfunktion der Standardnormalverteilung bezeichne.
Dann ist
\begin{equation}
\kappa := \left[g - \sqrt{\mathbb{V}_{a}(g)}z_{\gamma}, g + \sqrt{\mathbb{V}_{a}(g)}z_{\gamma}\right]
\end{equation}
ein asymptotisches $\gamma$-Konfidenzintervall für die standardisierte Effektstärke $\delta$.
\end{theorem}

Bemerkungen


* Das betrachtete Konfidenzintervall wurde von @hedges1985 (S.86) vorgeschlagen.
* Wir nutzen hier $\gamma$ für das Konfidenzlevel, da $\delta$ schon belegt ist.
* $\kappa$ entspricht einem  Konfidenzintervall für den Erwartungswert der Normalverteilung bei bekannter Varianz.
* In der Anwendung wird man $\mathbb{V}_{a}(g)$ durch seinen Schätzer $\hat{\mathbb{V}}_{a}(g)$ ersetzen.
* Asymptotische Konfidenzintervalle werden auch *Konfidenzintervalle von Wald-Typ* genannt.

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\underline{Beweis}

Wir müssen zeigen, dass 
\begin{equation}
\mathbb{P}(\kappa \ni \delta) = \gamma.
\end{equation}
Dazu halten wir zunächst fest, dass 
\begin{align}
\begin{split}
g \stackrel{a}{\sim} N\left(\delta, \mathbb{V}_{a}(g) \right).
\end{split}
\end{align}
Mit dem Theorem zur $Z$-Transformation gilt dann
\begin{equation}
Z_g := \frac{g - \delta}{\sqrt{\mathbb{V}_{a}(g)}} \sim N(0,1).
\end{equation}


Weiterhin gilt per Definition von $z_\gamma$, dass
\begin{equation}
\mathbb{P}\left(-z_\gamma \le Z_g \le z_\gamma \right) = \gamma.
\end{equation}

# Standardisierte Effektstärkeschätzung in Einzelstudien
\footnotesize
\underline{Beweis (fortgeführt)}

Aus der Definition eines $\gamma$-Konfidenzintervalls folgt dann
\begin{align}
\begin{split}
\gamma 
& = \mathbb{P}\left(-z_\gamma \le Z_g \le z_\gamma \right) \\
& = \mathbb{P}\left(-z_\gamma \le  \frac{g - \delta}{\sqrt{\mathbb{V}_{a}(g)}} \le z_\gamma \right) \\
& = \mathbb{P}\left(-z_\gamma\sqrt{\mathbb{V}_{a}(g)} \le g - \delta \le z_\gamma\sqrt{\mathbb{V}_{a}(g)} \right) \\
& = \mathbb{P}\left(-g -z_\gamma\sqrt{\mathbb{V}_{a}(g)} \le - \delta \le -g + z_\gamma\sqrt{\mathbb{V}_{a}(g)} \right) \\
& = \mathbb{P}\left(g + z_\gamma\sqrt{\mathbb{V}_{a}(g)} \ge \delta \ge g - z_\gamma\sqrt{\mathbb{V}_{a}(g)} \right) \\
& = \mathbb{P}\left(g - z_\gamma\sqrt{\mathbb{V}_{a}(g)}  \le \delta \le g + z_\gamma\sqrt{\mathbb{V}_{a}(g)} \right) \\
& = \mathbb{P}\left(\left[g - \sqrt{\mathbb{V}_{a}(g)}z_\gamma,g + \sqrt{\mathbb{V}_{a}(g)}z_\gamma\right]  \ni \delta \right) \\
& = \mathbb{P}(\kappa \ni \delta) 
\end{split}
\end{align}
und damit ist alles gezeigt.


# Standardisierte Effektstärkeschätzung in Einzelstudien
\small
\vspace{2mm}
Simulation eines asymptotischen 95%-Konfidenzintervalls für die SES  

\vspace{1mm}
\tiny
\setstretch{1}
```{r, echo = T}
set.seed(0)                                                       # Zufallsgeneratorstate
sim            = 1e2                                              # Anzahl Realisierungen
mu_t           = 2                                                # Erwartungswertparameter Treatment
mu_c           = 0                                                # Erwartungswertparameter Control
sigma          = 1                                                # Varianzparameter
delta          = (mu_t - mu_c)/sigma                              # wahre, aber unbekannte, SES
gamma          = 0.95                                             # Konfidenzlevel
z_gamma        = qnorm((1+gamma)/2)                               # Konfidenzlevelkonstante
n_t            = 100                                              # Treatmentgruppenumfang
n_c            = 100                                              # Kontrollgruppenumfang
n              = (n_t*n_c/(n_t+n_c))                              # Stichprobenumfangparameter
m              = n_t + n_c - 2                                    # Freiheitsgradparameter
c_m            = (gamma(m/2))/(sqrt(m/2)*gamma((m-1)/2))          # Biaskorrekturfaktor
gs             = rep(NaN, sim)                                    # Hedges' g Arrayinitialisierung
vs             = rep(NaN, sim)                                    # asymptotische Varianzarray
kappa          = array(rep(NaN, sim*2), dim = c(2,sim))           # Konfidenzintervallarray   
for(i in 1:sim){                                                  # Simulationsiterationen
   y           = matrix(rep(NaN,n_t+n_c), ncol = 2)               # Datenanarrayinitialisierung  
   y[,1]       = rnorm(n_t, mu_t, sigma)                          # Datengeneration Treatmentgruppe
   y[,2]       = rnorm(n_c, mu_c, sigma)                          # Datengeneration Kontrollgruppe
   ybar        = apply(y,2,mean)                                  # Gruppenmittelwerte   
   s2          = apply(y,2,var)                                   # Gruppenvarianzen
   s           = sqrt(((n_t-1)*s2[1] + (n_c-1)*s2[2])/m)          # gepoolte Standardabweichung
   gs[i]       = c_m*(ybar[1]-ybar[2])/s                          # Hedges' g  
   vs[i]       = ((n_t+n_c)/(n_t*n_c))+(gs[i]^2)/(2*(n_t+n_c))    # Varianzschätzer
   kappa[1,i]  = gs[i] - sqrt(vs[i])*z_gamma                      # untere Konfidenzintervallgrenze
   kappa[2,i]  = gs[i] + sqrt(vs[i])*z_gamma                      # obere  Konfidenzintervallgrenze
}           
```

# Standardisierte Effektstärkeschätzung in Einzelstudien
\small
\vspace{2mm}
Simulation eines asymptotischen 95%-Konfidenzintervalls für die SES
  
```{r, eval = F, echo = F}
pdf(
file         = "./3_Abbildungen/eva_3_konfidenzintervalle.pdf",
width       = 7,
height      = 4)
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(3,2,0),
xaxs        = "i",
yaxs        = "i",
xpd         = TRUE,
font.main   = 1,
cex         = 1,
cex.main    = 1)
P_idx       = rep(NaN,sim)                                                        
P_idx[delta < kappa[1,] | delta > kappa[2,]] = 3                       
plot(
1:sim,
gs,
type     = "p",
xlim     = c(0,100),
ylim     = c(1,3),
xlab     = "Simulationen",
ylab     = "",
pch      =  19,
cex      =  .5)
arrows(
x0       = 1:sim,
y0       = kappa[1,1:sim],
x1       = 1:sim,
y1       = kappa[2,1:sim],
code     = 3,
angle    = 90,
length   = 0.01,
lwd      = .7)
lines(
1:sim,
rep(delta, sim),
col      = "gray80",
lty      = 1)
lines(
1:sim,
P_idx,
type    = "p",
pch     = 13,
col     = "darkorange")
dev.off()
```

```{r, echo = FALSE, out.width = "100%", fig.align = "center"}
knitr::include_graphics("./3_Abbildungen/eva_3_konfidenzintervalle.pdf")
```  

# 
\vfill
\setstretch{3}
\large
Motivation 

Standardisierte Effektstärkeschätzung in Einzelstudien

**Anwendungsbeispiel**

Selbstkontrollfragen
\vfill 


# Anwendungsbeispiel

```{r, echo = FALSE, out.width = "55%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_schaeuffele_abstract.pdf")
```

\flushright
@schaeuffele2024

# Anwendungsbeispiel

\small
A systematic review and meta-analysis of TD-CBT for emotional disorders

\footnotesize

"All analyses were conducted in R (v.4.3.1), using the metafor (v.4.2-0),
meta (v.6.5-0) and dmetar packages (v.0.1.0). **We calculated controlled effect 
sizes for the difference between the transdiagnostic treatment and the control 
conditions in main outcomes (depression and anxiety) at posttreatment (relative efficacy),
using the bias-corrected Hedges’ g and the 95% CI. These were calculated by 
subtracting the mean posttreatment score of the transdiagnostic
condition from the mean score of the control condition, divided by the pooled 
standard deviation of both conditions. Values of 0.2, 0.5 and 0.8 of Hedges’ g 
represent a small, moderate and large effect size, respectively.**" 

*Data and Code availability*. The data that support the findings of this study, along with 
data collection templates, are publicly available at the Open Science Framework
and can be accessed at \url{https://osf.io/ta4fg/}. Custom analysis code that 
supports the findings of this study is publicly available at the Open Science 
Framework and can be accessed at \url{https://osf.io/ta4fg/}.

\flushright
@schaeuffele2024

# Anwendungsbeispiel
\small
\vspace{2mm}
Identifikation von 56 relevanten RCTs mit n = 6916 Teilnehmer:innen ([\textcolor{blue}{PRISMA Flowchart}](https://www.prisma-statement.org/prisma-2020-flow-diagram))

```{r, echo = FALSE, out.width = "60%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_schaeuffele_prisma.pdf")
```

\footnotesize
\flushright
@schaeuffele2024


# Anwendungsbeispiel
\small
\vspace{2mm}
Einschätzung des Verzerrungsrisikos anhand des [\textcolor{blue}{Cochrane Risk of Bias Tools}](https://methods.cochrane.org/risk-bias-2) 
\vspace{1mm}

```{r, echo = FALSE, out.width = "40%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_schaeuffele_cochrane_robt_1.pdf")
```
\vspace{3mm}
```{r, echo = FALSE, out.width = "70%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_schaeuffele_cochrane_robt_2.pdf")
```

\footnotesize
\flushright
@schaeuffele2024


# Anwendungsbeispiel
\small
\vspace{2mm}
Beispielstudien

```{r, echo = FALSE, out.width = "80%", fig.align = "center"}
knitr::include_graphics("./3_Abbildungen/eva_3_schaeuffele_beispielstudien.pdf")
```  

\footnotesize
\flushright
@schaeuffele2024

# Anwendungsbeispiel
\vspace{2mm}
\small

Reformatierung des Datensatzes

\vspace{2mm}
\tiny
\setstretch{1.2}
```{r, echo = T}
# R Pakete
library(tidyr)
library(dplyr)

# Dateneinlesen, rearrangieren, NA Ausschluss (nach https://osf.io/ta4fg/)
load("3_Daten/td_ma.RData")
data_dep_between_post <- data_dep_between %>% 
                           arrange(match(comparison, c("DS-CBT", "TAU", "other", "wait-list")), 
                                 study_name, match(setting, c("individual", "group", "internet-based"))) 
DS  <- data_dep_between %>% drop_na(c(post_tau_m, post_tau_sd, post_td_m, post_td_sd, post_tau_n, post_tau_sd))

# Reformatierung
D       = data.frame(id         = DS$study_id,              # Studien ID
                     reference  = DS$study_name,            # Studienreferenz
                     control    = DS$comparison,            # Kontrollbedingung (DS, TAU, Other, WL)
                     setting    = DS$setting,               # Studiensetting (individual, internet-based, group)
                     outcome    = DS$questionnaire,         # Primäres Ergebnismaß
                     n_t        = DS$post_td_n,             # n Treatmentgruppe 
                     n_c        = DS$post_tau_n,            # n Kontrollgruppe 
                     m_t        = DS$post_td_m,             # Mittelwert Treatmentgruppe
                     m_c        = DS$post_tau_m,            # Mittelwert Kontrollgruppe
                     sd_t       = DS$post_td_sd,            # Standardabweichung Treatmentgruppe 
                     sd_c       = DS$post_tau_sd)           # Standardabweichung Kontrollgruppe

# Speichern des reformatierten Datensatzes
write.csv(D, "./3_Daten/TD-CBT.csv", row.names = FALSE)
```

# Anwendungsbeispiel
\vspace{2mm}
\footnotesize
n_ Gruppengröße, m_ Mittelwert, sd_ Standardabweichung für _t Treatment, _c Control


\tiny
\setstretch{.8}
```{r}
D       = read.csv("./3_Daten/TD-CBT-C.csv")        
print(D[1:30,], digits = 1, row.names = FALSE)
```

# Anwendungsbeispiel
\vspace{2mm}

\footnotesize
n_ Gruppengröße, m_ Mittelwert, sd_ Standardabweichung für _t Treatment, _c Control


\tiny
\setstretch{.8}
```{r}
D       = read.csv("./3_Daten/TD-CBT-C.csv")     
print(D[31:60,], digits = 1, row.names = FALSE)
```

# Anwendungsbeispiel
\vspace{2mm}
\footnotesize
Hedges $g$, asymptotischer Varianzschätzer and asymptotisches 95%-Konfidenzintervall

\vspace{2mm}
\setstretch{1.2}
\tiny

```{r, echo = T}
D       = read.csv("./3_Daten/TD-CBT.csv")                               # Einlesen des Datensatzes
k       = nrow(D)                                                        # Studienanzahl
delta   = 0.05                                                           # Konfidenzlevel
z_delta = qnorm((1 + delta)/2)                                           # Konfidenzintervallkonstante
D$hgi   = rep(NaN,k)                                                     # Hedges' g
D$vgi   = rep(NaN,k)                                                     # asymptotische Varianz
D$ci.lb = rep(NaN,k)                                                     # untere CI Grenze    
D$ci.ub = rep(NaN,k)                                                     # obere  CI Grenze
for(i in 1:k){                                                           # Studieniterationen    
    n_t        = D$n_t[i]                                                # Umfang Treatmentgruppe
    n_c        = D$n_c[i]                                                # Umfang Kontrollgruppe
    bar_y_t    = D$m_t[i]                                                # Mittelwert der Treatmentgruppe
    bar_y_c    = D$m_c[i]                                                # Mittelwert der Kontrollgruppe
    s2_t       = D$sd_t[i]**2                                            # empirische Varianz der Treatmentgruppe
    s2_c       = D$sd_c[i]**2                                            # empirische Varianz der Kontrollgruppe
    s          = sqrt(((n_t-1)*s2_t + (n_c-1)*s2_c)/(n_t+n_c-2))         # gepoolte Standardabweichung
    es         = bar_y_c - bar_y_t                                       # Effektstärke   
    d          = (bar_y_c - bar_y_t)/s                                   # Cohen's d
    m          = n_t + n_c - 2                                           # Freiheitsgradparameter
    c_m        = (gamma(m/2))/(sqrt(m/2)*gamma((m-1)/2))                 # Biaskorrekturfaktor
    D$hgi[i]   = c_m*d                                                   # Hedges' g 
    D$vgi[i]   = 1/n_t + 1/n_c +(D$hgi[i]^2)/(2*(n_t+n_c))               # Geschtätzte asymptotische Varianz  
    D$ci.lb[i] = D$hgi[i] - z_delta*sqrt(D$vgi[i])                       # untere asymptotische KI Grenze
    D$ci.ub[i] = D$hgi[i] + z_delta*sqrt(D$vgi[i])}                      # obere asymptotische KI Grenze
write.csv(D, "./3_Daten/TD-CBT-GI.csv", row.names = FALSE)               # Speichern
```


# Anwendungsbeispiel
\vspace{2mm}
\footnotesize
Hedges' $g$ und asymptotischer Varianzschätzer mit `metafor`
\vspace{2mm}
\tiny
```{r, echo  =T}
library(metafor)    
D           = read.csv("./3_Daten/TD-CBT-GI.csv")                       # Einlesen des Datensatzes
D           = escalc(                                                   # escalc() aus metafor
data        = D,                                                        # Datensatz
measure     = "SMD",                                                    # Hedges g
m1i         = m_c,                                                      # Mittelwerte Treatmentgruppe
sd1i        = sd_c,                                                     # Standardabweichungen Treatmentgruppe
m2i         = m_t,                                                      # Mittelwerte Kontrollgruppe
sd2i        = sd_t,                                                     # Standardabweichungen Kontrollgruppe
n1i         = n_c,                                                      # Umfang Treatmentgruppe
n2i         = n_t,                                                      # Umfang Kontrollgruppe
slab        = id)                                                       # Studien ID
write.csv(D, "./3_Daten/TD-CBT-GI.csv", row.names = FALSE)              # Speichern
```

# Anwendungsbeispiel
\vspace{2mm}
\footnotesize

Hedges' $g$, asymptotischer Varianzschätzer und asymptotisches 95%-Konfidenzintervall: `hgi`, `vgi`, `ci.lb`, `ci.ub` 

\tiny
\setstretch{.8}
```{r}
print(D[1:30,c(2,12,13,14,15)], digits = 1)
```



# Anwendungsbeispiel
\vspace{2mm}
\small
Forestplot mit `metafor`

\vspace{1mm}
\setstretch{1.2}
\tiny

```{r, echo = T, eval = F}
# figure setup
library(latex2exp)
library(metafor)
pdf(file = "./3_Abbildungen/eva_3_forest.pdf", width = 12, height = 18)                                                                      
par(                                                                   
family      = "sans",                                                 
mfcol       = c(1,1),                                                
pty         = "m",                                                   
bty         = "l",                                                   
lwd         = 1,                                                      
las         = 1,                                                      
mgp         = c(2,1,0),                                               
xaxs        = "i",                                                    
yaxs        = "i",                                              
font.main   = 1) 

# forest plot
D           = read.csv("./3_Daten/TD-CBT-GI.csv")                       # Einlesen des Datensatzes
res         = rma(yi=yi, vi=vi, data = D)                               # Schätzen des Random Effects Models
forest(                                                                 # metafor forest() Funktion
res,                                                                    # Random-effect-model object
slab        = paste(D$reference),                                       # Studienreferenzen  
alim        = c(-2,4),                                                  # Hedges g Spanne
header      = paste0("Author(s) and Year"))                             # header for study label and SMD
dev.off()
```

# Anwendungsbeispiel
\small
Forestplot mit `metafor` 

\footnotesize
* Die 95%-Konfidenzintervalle entsprechen nicht denen nach @hedges1985 (S. 86) vorgeschlagenen.

\vspace{-2mm}
```{r, echo = FALSE, out.width = "40%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_forest.pdf")
```


# 
\vfill
\setstretch{3}
\large
Motivation 

Standardisierte Effektstärkeschätzung in Einzelstudien

Anwendungsbeispiel 

**Selbstkontrollfragen**
\vfill


# Selbstkontrollfragen

\footnotesize
\setstretch{3}
1. Geben Sie die Definition von Cohen's $d$ im Treatment- und Kontrollgruppen-Design wieder.
1. Geben Sie die Definition des Einzelstudienmodells (ESMs) wieder.
1. Geben Sie die Definition des Effektstärkeschätzers im ESM wieder.
1. Geben Sie Aussage (1) und (2) des Theorems zu den Eigenschaften des Effektstärkeschätzers im ESM wieder.
1. Geben Sie das Theorem zum Unverzerrten Effektstärkeschätzer im ESM - Hedges' $g$ wieder.
1. Geben Sie das Theorem zur Asymptotischen Normalverteilung von Hedges' $g$ wieder.

# Appendix
\footnotesize
\begin{definition}[Nichtzentrale $t$-Zufallsvariable]
\justifying
$T$ sei eine Zufallsvariable mit Ergebnisraum $\mathbb{R}$ und WDF
\begin{equation}
p : \mathbb{R} \to \mathbb{R}_{>0}, t \mapsto p(t) :=
\frac{1}{2^{\frac{\nu-1}{2}}\Gamma\left(\frac{\nu}{2} \right)(\nu \pi)^{\frac{1}{2}}} 
\int_{0}^\infty \tau^{\frac{\nu-1}{2}} \exp\left(-\frac{\tau}{2}\right)
\exp\left(-\frac{1}{2}\left(t \left(\frac{\tau}{\nu}\right)^{\frac{1}{2}} - \mu \right)^2 \right)\,d\tau.
\end{equation}
Dann sagen wir, dass $T$ einer nichtzentralen $t$-Verteilung mit 
Nichtzentralitätsparameter $\mu$ und Freiheitsgradparameter $\nu$ unterliegt 
und nennen $T$ eine \textit{nichtzentrale $t$-Zufallsvariable mit Nichtzentralitätsparameter
$\mu$ und Freiheitsgradparameter $\nu$}. Wir kürzen dies mit $T \sim t(\mu, \nu)$ ab. 
Erwartungswert und Varianz einer nichtzentral $t$-verteilten Zufallsvariable $T$ 
mit Nichtzentralitätsparameter $\mu$ und Freiheitsgradparameter $\nu > 1$ ergeben sich zu 
\begin{equation}
\mathbb{E}(T) = \mu \sqrt{\frac{\nu}{2}}\frac{\Gamma((\nu - 1)/2)}{\Gamma(\nu/2)} 
\mbox{ und }
\mathbb{V}(T) 
= \frac{\nu(1 + \mu^2)}{\nu - 2} - \frac{\mu^2 \nu}{2}\left(\frac{\Gamma((\nu - 1)/2)}{\Gamma(\nu/2)}\right)^2.
\end{equation}
\end{definition}

Bemerkung

* Nichtzentrale $t$-Zufallsvariablen sind für die Testgütefunktion des T-Tests essentiell.
* Für die Herleitung von Erwartungswert und Varianz verweisen wir auf @hogben1961.

# Appendix
Wahrscheinlichkeitsdichtefunktionen spezieller nichtzentralen $t$-Zufallsvariablen.

```{r, echo = F, eval = F}
options(warn=-1)                                                                # warning off
t_min     = -5                                                                  # Minimum T-Wert
t_max     = 30                                                                  # Maximum T-Wert
t_res     = 1e3                                                                 # T-Wert Auflösung
t         = seq(t_min, t_max, len = t_res)                                      # T-Raum
delta     = c(0,5,15)                                                           # Nichtzentralitätsparameter
nu        = c(5, 30)                                                            # Freiheitsgrade
p         = cbind(
            matrix(dt(t, nu[1], delta[1]),nrow=length(t)),
            matrix(dt(t, nu[2], delta[1]),nrow=length(t)),
            matrix(dt(t, nu[1], delta[2]),nrow=length(t)),
            matrix(dt(t, nu[2], delta[2]),nrow=length(t)),
            matrix(dt(t, nu[1], delta[3]),nrow=length(t)),
            matrix(dt(t, nu[2], delta[3]),nrow=length(t)))

# Visualisierung
pdf(
file        = "./3_Abbildungen/eva_3_nichtzentrale_t_wdf.pdf",
width       = 7,
height      = 4.5)
library(latex2exp)
par(
family      = "sans",
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1.2)
matplot(
t,
p,
type        = "l",
lty         = c(1,2,1,2,1,2),
col         = c("gray10", "gray10", "gray50", "gray50", "gray70", "gray70"),
lwd         = 2,
xlab        = "T",
ylab        = "",
ylim        = c(0,.4),
main        = TeX("$t(T;\\mu,\\nu)$"))
legend(
18,
.4,
c(TeX("$\\mu = 0 , \\,\\,\\,\\nu = 5$"),
  TeX("$\\mu = 0 , \\,\\,\\, \\nu = 30$"),
  TeX("$\\mu = 5 , \\,\\,\\,\\nu = 5$"),
  TeX("$\\mu = 5 , \\,\\,\\,\\nu = 30$"),
  TeX("$\\mu = 15, \\, \\nu = 5$"),
  TeX("$\\mu = 15, \\, \\nu = 30$")),
lty         = c(1,2,1,2,1,2),
col         = c("gray10", "gray10", "gray50", "gray50", "gray70", "gray70"),
lwd         = 2,
bty         = "n",
seg.len     = 1.75)
dev.off()
```

```{r, echo = FALSE, out.width = "90%", fig.align = "center"}
knitr::include_graphics("3_Abbildungen/eva_3_nichtzentrale_t_wdf.pdf")
```


# Referenzen
\footnotesize